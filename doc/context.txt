
1. Intro

Our goal here is to identify techniques for implementing conveyances while using the C
language.  C is chosen because it is more portable than assembly. Later we will create
enhancements to C, or possibly a new language, which will have direct support for these
techniques.

In C there is an outermost file wide lexical scope.  Variables and functions may be defined
at file scope scope. Such variables are statically allocated.

Within a function definition matching curly braces may be used to created nested levels of
lexical scope.  Programs and statements within a given nesting level may see variables declared at
outer nesting levels, but not those at deeper levels.  By default such variables will
be allocated on the stack.

The C standard only allows for functions to be declared at file scope. Functions are
statically allocated, i.e. have fixed locations in memory.  There is an extern keyword for
declaring functions who's definitions were given in other source files. According to the C
standard, functions may not be declared at nested scope levels.  The compiler will issue
an error and refuse to compile such funcitons.

In the definition of the TM library we made use of the technique of passing in locally
defined, often anonymous, continuation functions as arguments.  In C we may pass in
function pointers as arguments to functions, which is probably how the lambda passing
is implemented anyway, however we may not locally define such functions due to the restriction
on nesting levels.  Furthermore locally defined functions in Lisp may take advantage
of variables what are within lexical scope without passing them in as arguments.  This has
proven to be a natural thing to do when defining a function at a lower nesting level of
lexical scope..

Gcc provides an extension for defining nested functions, and these nested functions may make
use of variables within lexical scope.  These functions may not be anonymous but that is
only a detail.  This nicely facilitates the programming style of using continuations. 

However, we are using conveyances rather than functions. We can emulated nested conveyances
using conveyances encapsulated within functions, as described further below, but we
would rather have a direct implementation of nested conveyances.

We are using a sort of hack to implement conveyances in C.  Accordingly we use a label
followed by an open brace that defines a nested lexical scope.  Then within the conveyance
we follow a continuation by using the 'continue_from' macro.  This hack is not that much
different than how functions are implemented.  After all, all this stuff has to be turned
into assembly language, and that typically has labels along with branch, and call instructions.
Whereas a C function will have a label and be invoked through a call, our conveyance will
have a label and be continued to with an branch instruction.

There is a limitation in the C standard where labels are always taken to be at function
scope no matter where they occur in the lexical scope hierarchy.  However, thankfully,
Gcc has another extension that lets us put labels into th lexcial hierarchy by declaring
them after an opening brace.

The second problem we need to solve is that of sharing variables at an outer lexical scope
with the conveyance that is defined within that scope. This is a challenge because conveyances
do not make use of the stack.  Where as nested functions and lambads may just reach up
in the stack to find such variables, the local variables of a conveyance are on a data pad
that is within an union with other data pads, so by the time we reach a nested function the
out scope variables, so to speak, may well have been overwritten.

2. Analysis of the outerscope variable passing problem

We have a situation like the following:

   .--c1
   |  |
   |  [c2]
    \ |   \
      c3 
      | \

Here c1 is our outer lexical scope conveyance.  c3 is our nested conveyeance that has been
defined within that scope.  [c2] is a continuation call into conveyance c2.  Its
definition lies elswhere.  Here c2 continues into c3 which is again withing the c1 lexical
scopes.  It is common that a conveyance will have multiple continuations, so c3 might just
be one among a number of possibilities.  c3 will also continue off somewhere, as all
conveyances that do not exit the program will have at least one continuation.

Consider this example, here TM2x·dealloc_heap is the outer conveyance, c1.  We will call
TM2x·destruct, which corresponds to [c2] in our diagram, and then TM2x·destruct will
continue on to the nested conveyance called 'success, which corresponds to c3.

    TM2x·dealloc_heap:{

      // Swaps the args and locals pads.
      Conveyance·swap(); 

      // Makes lc0 an alias for Conveyance·Locals_pt->dealloc_heap.
      register struct TM2x·dealloc_heap0 *lc0 = &Conveyance·Locals_pt->dealloc_heap;

      // Puts arguments for TM2x·destruct on to the arguments pad
      struct TM2x·destruct0 *ar = &Conveyance·Args_pt->TM2x·destruct;
      ar->tape = lc0->tape;
      ar->nominal = &&success; // this is a reference to our nested conveyance
      continue_from TM2x·destruct;

      // a nested conveyance definition
      success:{
        free( <message>->tape);
        continue_from  <message>->nominal;
        cend; 
      }

      cend; // it is an error to reach cend
    }

Our c3 analog, 'TM2x·dealloc_heap', accesses variables at the 'outer scope', namely
lc0->tape and lc0->nominal.  lc0->nominal is a pointer to the nominal continuation for
TM2x·dealloc_heap, the outer conveyance.  That continuation is set to 'success'.  We
may think of the values lc0->tape and lc->nominal as messages that are sent from c1 to
c3.

If the programmer has control over c1, c2, and c3, then he or she may design the code so
that c2 relays the message for c1 by making it an argument of c2.  However, if the
programmer desires, or is comppelled, to keep the definitions of c1 and c3 as separate
code maintinance tasks, a different solution will be needed.  A solution that does not
depend up on how c2 uses its data pad.

3. Difficulites in passing such messages through the stack

When we do a function call, the function is given a stack frame.  Upon return from
the function the stack frame is popped.  Thus local variables are allocated and
cleaned up. Our conveyances do not make use of the stack, but they do make use
of nested lexical scope.

By lexical scoping rules in C a variable may only be used after it is declared, and may
not be referenced after the next closing brace at that scope level.  Hence, a programmer
might conclude that this structure is parallleled in the generated code.  I.e. conclude
that when the compiler would insert code to push variables declared within a lexcial
scope at the pointer where the opening brace occurs, or even where the local variable
is declared, and then would generate code to pop such local variables off the stack
at the place where the matching closing brace occurs in the source.  Such a compilation
strategy would also have to add pop instructions before branches that left the code
generated from said lexcial scope.

If C compilers generated code in this manner, i.e. code that dynamically parralleled the
static lexical scope structures, then it would be possible for c1 to declare variables to
be sent to c3 in the normal fashion, and it would work just like it works for functions,
such variables would get allocated on the stack upon entering the conveyance, and then
popped off when leaving it, because our conveyances always start with an opening brace and
end with a closing one.

However, all that is just wishful thinking.  C compilers are not obligated to create
parallel structures to the lexical scopes in the generated code. They are perfectly free
to declare the variables to be used at any scoping level when the program starts, and then
to ditch them when the program exits - or anything else inbetween.  The only constraint is
that the compiler must respect the C specification and maintain the appearence of
variables only being available within their correpsonding lexical scopes.

And indeed this is what an example I coded up in the the try directory is doing.
Everything gets reserved upon the entrance to main, and all get popped off at the end of
the program.  This happens independent of the optimization level. With this approach the
compiler need not generate pops upon leaving a lexical scope.  However this simplification
comes at a cost, in that if, due to the vagaries of the computation, we never use a
particular lexical scope, the variables declared in that scope still take up memory.  I
used this effect to cause the program shown in the try directory to crash due to not
having enough stack space, though it actually only needs a few bytes of space.

As a side note, C++ compilers do guarantee that object destructors will be called when
leaving a lexical scope, even if that departure is due to a 'goto'.  But this does not
help us here, because even if destructors are called, all of our messages still might end
up allocated on the stack without ever being deallocated.  We need a deallocation
guarantee, not a destructor call guarantee.  Note the stack will not grow at run time
due to this.  There will be one message allocation per conveyance, but all the messages
from all the convyances will take up space independent of the path taken at run time.

We could fource the push pop parallel structures to be placed into the generated code by
using some inline asm functions and explicit calls to them.  However, right now we do not
use the stack at all, so we really should have a stack free method of passing messages.
If I have to write some new code for this and add explicit calls, I will first attempt to
implement a stackless approach.

4. Shared pads.

When we have control over c1, c2, and c3 code, we may simply have c2 relay the message.
In situations where we do not have such control, then we will use a method of shared
message pads. 

We add a data pad in analogy to our arguments pad.  Both c1 and c3 know about this pad and
may use it to relay a message.  All such pads throughout our code, which can not be in in
simultaneous use are placed in union, just as we do with the argument pads.  Hence we
will end up with N such pads, where N is the static nesting levels of message passing we
find in our source code.




