
* Intro

  Our goal here is to identify techniques for implementing conveyances while using the C
  language.  I want to be close to the hardware so I chose C which is one step away from
  assembly, though an assembler would surely have had a better macro processor.

* Conveyances and Continuation

  A conveyance is analogous to a function.  Where as a function is ‘called’, a conveyance
  is ‘conveyed’.

  A conveyance is defined by starting with a `cdef` macro and ending with a `cend` macro.

  Due to limitations of C labels which are used in the cdef macro, currently a conveyance
  may not be declared at global scope. Rather a conveyance must be declared within a function.


````
      cdef(name){


        cend;
      }
````

* encapsulation

  An encapsulation is a function like object used to hold conveyances. The definition of
  an encapsulation starts with the `encapsulation(name)` macro, and ends with an `eend` macro.

  By contract with the programmer:

  1. We required that all paths of execution stemming from the point of entry will lead to
  a `leave_to` macro call. If we hit the `eend` macro, bad things will happen.

  2. The return value must be one of the ConveyancePtrs that was passed into the
  encapsulation.

  3. Conveyances must be declared on the first line of a lexical scope they appear in. (If
  they are not declared, then they will all appear at the top level function scope
  independent of where they occur in lexical scope.)


````
      encapsulation(f)(int i ,ConveyancePtr not_five ,ConveyancePtr five){
        Conveyance a ,b;

        int j = 7;
        ink k = 9;

        convey a;

        cdef(a){
          convey b;
          cend;
        }

        cdef(b){
          if( i + j + k == 21 )
            leave_to five;
          else
            leave_to not_five;
          cend;
        }

        eend;
      }
````

  Here `f` accepts as arguments an integer and two `ConveyancePtrs`. The conveyances `a` and `b`
  are defined inside the lexical scope of `f`, and neither `a` nor `b` convey to a point
  outside of `f`.

  This function picks one of the passed in conveyance pointers to `leave_to`. Here the
  term ‘leave’ refers to leaving the context defined by the encapsulation.  By contract
  with the programmer, an encapsulating function may only `leave_to` a `ConveyancePtr`
  argument value that was passed in.

  Because `leave_to` returns a conveyance pointer we may convey to a an encapsulation, as
  shown here:

````
    int main(){
      Conveyance not_five ,five;

      int i = 5;

      convey *f( i ,&&not_five ,&&five);

      cdef(not_five){
        printf("%d" ,i);
        return 1;
        cend;
      }

      cdef(five){
        printf("%d" ,i+1);
        return 0;
        cend;
      }

    }
````

  Here `not_five` and `five` are conveyances defined in the `main()` function.  The call
  to `f` will continue through to be either `not_five` or to `five`. An examination of `f`
  will show that it always returns the five continuation. Hopefully the optimizer would
  catch on to that and eliminate the function call and the `not_five` conveyance.

  Variables declared in an encapsulating function, as for all functions, are by default
  declared in the function's stack frame.  C calls this the ‘auto’ storage class. Thus,
  function encapsulated conveyances may share the variables declared in the encapsulation.
  Together we call these variables the ‘context’ of the conveyances.

  Though functions normally have only one point of return, we use a trampoline to
  effectively give encapsulating functions multiple points of return. If we had more
  control over compilation we could eliminate the return and trampoline, and instead pop
  the context off the stack and convey directly to the outer scope. Perhaps someday the
  compiler optimizer will recognize such patterns and do this replacement for us. Also
  likely is that we will end up with a new computer language with native support for
  conveyances.

  Gcc has a nested function extension which makes it possible to define encapsulating
  functions inside of other functions. Nested functions may make use of variables found
  in the outer lexical scope context.

* Pads

  A data pad is a memory buffer shared by multiple conveyances. It may be bound to any
  number of types. In C we will declare these types in advance as structs, causing a pad
  to be a union of structs.

  Because conveyances do not return, there is no reason to place their arguments
  nor a return address on to the stack.  Instead, to pass arguments to a conveyance
  we write those arguments to a pad, and then the conveyance pulls them off the
  pad as needed.  We will then recycle the pad to pass arguments to
  the next conveyance.  

  We may do a similar thing with a call to an encapsulation.  Values passed as parameters
  to an encapsulation become part of the context encapsulation context.  They may then be
  shared by the encapsulated conveyances. If we have arguments that are not to become
  messages between the conveyances, i.e. not to become part of the context, then we may
  use a pad to pass these arguments to the encapsulation.

  While using a pad, a call to a function encapsulation of conveyances might look like
  this:

  ````
    AR(ar ,Inclusive·3opLL ,0);
    ar->a0 = lc->element_n;
    ar->a1 = lc->element_byte_n;
    ar->rpt = &cx->byte_n;
    convey *Inclusive·mul_ib(nominal ,gt_address_t_n);

  ````

  In this example, the AR macro sets up a pointer to point to the arguments pad. The
  arguments are then copied to the pad, and finally we convey the `Inclusive·mul_ib`
  encapsulation.

  The following example is what the `construct_elements` encapsulation might look like in
  the TM2x library. (I say might, because the final form has not yet been written.)  We
  make use of two pads.  One for arguments and one for local variables.  We often swap
  these upon entering an encapsulation so that we might more easily build the arguments
  pad for the next conveyance.  The LC macro sets up a pointer to point to the local pad.


  ````
  encapsulation(construct_elements)
    (
     ContinuationPtr nominal
     ,ContinuationPtr index_gt_n
     ,ContinuationPtr alloc_fail
     ){
    Conveyance scale ,construct_bytes ,local_index_gt_n ,local_nominal ,local_alloc_fail;
    Conveyance·swap();
    LC(lc ,TM2x·construct_elements ,1);

    tape = lc->tape;
    address_t byte_n;

    convey scale;

    cdef(scale){
      AR(ar ,Inclusive·3opLL ,0);
      ar->a0 = lc->element_n;
      ar->a1 = lc->element_byte_n;
      ar->rpt = &byte_n;
      convey Inclusive·mul_ib(&&construct_bytes ,&&local_index_gt_n);
      cend;
    };

    cdef(construct_bytes){
      AR(ar ,TM2x·construct_bytes ,0);
      ar->tape       = tape;
      ar->byte_n     = byte_n;
      convey TM2x·construct_bytes(&&local_nominal ,&&local_alloc_fail);
      cend;
    };

    cdef(local_index_gt_n){
      leave_to index_gt_n;
      cend;
    }

    cdef(local_nominal){
      leave_to nominal;
      cend;
    }

    cdef(local_alloc_fail){
      leave_to alloc_fail;
      cend;
    }


    cend;
  }
  ````

  It is too bad we need the local conveyances, `local_index_gt_n`, `local_nominal`, and
  `local_alloc_fail`.  Their sole purpose is to maintain the integrity of the
  encapsulation of context.  By having `TM2x·contruct_bytes` and `Inclusive·mul_ib` first
  convey locally we assure that the stack frame gets popped.  If we did not need to pop
  the stack frame, `TM2x·contruct_bytes` and `Inclusive·mul_ib` could convey directly to
  `index_gt_n`, `nominal`, and `alloc_fail`.

  The remainder of this document explores possibility of using conveyances without
  encapsulation.


* Mixing functions with shared conveyances

  Suppose we have defined a general use conveyance somewhere for purposes of sharing
  it. It might even be part of a conveyance library.  In such a case we might end up with
  code something like this:

````
    encapsulation(f)(conveyancePTR nominal ,conveyancePTR alloc_fail){

      ...

      struct cx *cx = &cxdat;
      struct lc *lc = &lcdat;

      AR(ar ,Inclusive·3opLL ,0);
      ar->a0 = lc->element_n;
      ar->a1 = lc->element_byte_n;
      ar->rpt = &cx->byte_n;
      ar->nominal = &&construct_bytes;
      ar->gt_address_t_n = lc->index_gt_n;
      convey Inclusive·mul_ib;

      cdef(construct_bytes){
        leave_to nominal;
        cend;
      };

      ...

    }
````

  Here lc is another data pad. cx is defined in the containing function, although that is
  not shown.

  `Inclusive·mul_ib` is a general use conveyance from a library. It was included into
  main.  It accepts two values, `a` and `b`, and writes a result to `rtp`.  This general
  use conveyance has two continuation arguments, `nominal` and `gt_address_t_n`.  If the
  product overflows the type used for representing the result, `Inclusive·mul_ib`
  continues with `gt_address_t_n` and no result is written.  Otherwise, it writes the
  result and continues with `nominal`.

  The line `convey Inclusive·mul_ib` will take us out of the containing function to
  execute code found in main. This violates our encapsulation contract, which is why we
  used the term ‘containing function’ instead of ‘encapsulating function’.

  The `Inclusive·mul_ib` conveyance will have been compiled against the stack frame of
  main, but when we take the continuation from `f` to `Inclusive·mul_ib` our stack pointer
  will be pointing to the stack frame for `f`, which is the wrong value for
  `Inclusive·mul_ib`. If the `Inclusive·mul_ib` conveyance does not use the stack, then
  things might work out; however, this would be hard to accomplish in the C language,
  because stack usage is deeply ingrained with the creation of locals and temporary
  variables. Even if we declare a value to hold a pointer to where local data is really
  stored, that pointer will be in a local variable.  If we try to get around this and
  declare that pointer to be of 'register' storage allocation class, C will not guarantee
  that it ends up in a register. The compiler is free to make it a local `auto`
  class variable instead.

  After running, if running does not seg fault, `Inclusive·mul_ib` conveys to either
  `construct_bytes` or to `lc->index_gt_n`.

  The conveyance `construct_bytes` was defined in the lexical scope for `f`.  Hence
  conveying to it will restore order to the universe.  `contruct_bytes` then returns
  from the function via `leave_to nominal`.

  Had we instead conveyed `lc->index_gt_n`, the stack to code correspondence would
  remain messed up because `lc->index_gt_n` is not defined within `f`.

  When all conveyances out of `f` return to `f`, we say that `f` ‘encapsulates
  conveyances with side trips’.  As described in this section, when using the C
  language this is a hazardous pattern.


* only function encapsulated conveyances

  If we were to require that all general use conveyances be function encapsulated, then we
  could use `convey` to call any of them without having stack pointer hazards.

  When a library function is small we can hope that the optimizer will make the call
  overhead go away by just including the contents of the function.  We can make this more
  likely by declaring the function inline. If it does not, then for a normal function call
  our arguments will be redundantly copied into function stack frames. We could avoid this
  redundancy by passing argument to encapsulated conveyances through a pad.

  Now suppose we have a large library of small function encapsulated conveyances, where
  the functions have  been declared inline. The compiler is free to ignore the inline
  keyword, but suppose that it doesn't.

  The consider a function that uses several of the library conveyances. The local variables
  for all the conveyances used by said function would end up simultaneously and separately
  allocated in said function's stack frame.  That would probably be more allocated space
  than needed, because, like arguments, the context of a conveyance is no longer needed
  after leaving the conveyance - unless a message is being passed though that context.

  Although there would probably be some inefficiency in storage allocation space allotted,
  this solution does successfully manage the allocation of contexts.

* only conveyances

  There are some problems with mixing function encapsulation with raw conveyances.
  Namely, the actual stack pointer vs what the function was compiled against could get out
  of alignment. (We could perhaps add some inline assembly as a hack, and avoid this
  problem, but such a thing then looks like encapsulation). In the prior section we
  avoided this misalignment by using only function encapsulated conveyances. In this
  section we discuss the flip side approach, where we have all conveyances, with the sole
  exception being one function where all the conveyances are included.  This one function
  would probably be `main()`.

  When we get rid of the encapsulating function we no longer have its stack frame for
  storing context. Any local variable that we declare will end up in `main()`'s stack
  frame. This would be inefficient because locals are not needed simultaneously, indeed
  none might not be needed at.

  We need context when variables are shared with conveyances that do not have a direct
  caller callee relationship.  Putting it more accurately, we need to be able to pass
  messages and having a context would be one way of accomplishing that.  So we will also
  need a means for addressing the allocation and deallocation of messages. The following
  subsections explore approaches for doing this.

** context pad

  This is a common pattern:

````
            .--c1
   context  |  |
            |  [c2]
             \ |   \
               c3   elsewhere
               | \
````

  Conveyance c1 shares context with c3.  Stated more accurately, the context of c1 is used
  for sending a message to c3.  This is accomplished by declaring the conveyance c3 within
  the lexical scope of c1.  This gives c3 the ability to access c1's context which is on
  c1's stack frame.  In the pattern here, c2 is a general use conveyance that will be continued
  into from c1, and then will continue to c3, or perhaps it will instead continue elsewhere.

  Here is an example of this pattern. Here `TM2x·dealloc_heap` corresponds to c1.
  `TM2x·destruct` corresponds to c2, and `success` corresponds to c3.

````
    cdef(TM2x·construct_elements){
      Conveyance construct_bytes;
      Conveyance·swap();
      LC(lc ,TM2x·construct_elements ,1);

      // CX is a macro that points `cx` at a context pad and gives it type
      CX(cx ,TM2x0 ,construct_elements);
      cx->tape       = lc->tape;
      cx->nominal    = lc->nominal;
      cx->alloc_fail = lc->alloc_fail;

      // AR is a macro that points `ar` to the arguments pad and gives it type.
      AR(ar ,Inclusive·3opLL ,0);
      ar->a0 = lc->element_n;
      ar->a1 = lc->element_byte_n;
      ar->rpt = &cx->byte_n;
      ar->nominal = &&construct_bytes;
      ar->gt_address_t_n = lc->index_gt_n;
      convey Inclusive·mul_ib;

      cdef(construct_bytes){
        AR(ar ,TM2x·construct_bytes ,0);
        ar->tape       = cx->tape;
        ar->byte_n     = cx->byte_n;
        ar->nominal    = cx->nominal;
        ar->alloc_fail = cx->alloc_fail;
        convey TM2x·construct_bytes;
        cend;
      };

      cend;
    }
````

  It just so happens that we defined c3 within c1´s lexical scope.  c1 will have
  continued into c2 before reaching c3, so c3 is a separate conveyance from c1.

  If c1 were a function instead of a conveyance, then it could declare local variables to
  share with c3. We would be back to function encapsulation.  However here c1 is not a
  function. Any variables declared in c1's lexical scope will end up on the encapsulating
  function's stack frame.  They can still be used for sharing, but as noted above for the
  inline function expansion, we would end up with all the local variables from all the
  conveyances separately allocated on the encapsulating functions stack frame, and that
  would be inefficient.

  Essentially this is a message passing problem, c1 desires to send a message
  to c3, but c2 stands in the way.

  The proposal of this section is to use pads for context. Because code can be nested, we
  will need one pad per nesting level.  The number of pads needed is determined by nesting
  depth in the source code.  Consider for example, if we add a loop to our diagram whereby
  c3 conditionally continues into c1.

````
            .--c1
   context  |  |
            |  [c2]
             \ |   \
               c3
               | \
              c1
````

   We still only need one context pad, because once we continue from c3 the context pad
   used to send a message from c1 to c3 is no longer needed.

   Now consider a structure where c2 that ‘somewhere else’ the unspecified other continuation
   for c2 mentioned is a continuation back into c1.


````
            .--c1-<--<.
   context  |  |      |
            |  [c2]   ^
             \ |   \__|
               c3
               | \


   (c1 c2)(+) c3

    c1 c2 c3
    c1 c2 c1 c2 c3

````
   Note our diagram is that of the static structure of the code.  At run time little gremlins
   will run around our graph thus executing the code.

   When, during execution, c2 continues to c1, c1 will still be holding context for c3.
   This context was computed the first time we continued into c1. However, no matter how
   many times we go through this subloop, we still only visit c3 one time. Hence upon the
   second trip through c1 we need to compute the cumulative message for c3.  So here too
   only one pad is needed. If the cumulative message gets longer on each loop, and we do
   not know how many loops will be taken, the pad will surely hold a pointer to the heap.
   There is still only one message, thus we still only need one pad.

   In the following diagram we include c3 in the continuation loop:

````
            .--c1-<--<.
   context  |  |      |
            |  [c2]   ^
             \ |   \  |
               c3     ^
               |  \___|


     (c1 c2 c3)(*)... | (c1 c2 c3)(*) c1 c2 ...


````
   When c3 continues into c1 the context is no longer needed, and thus the pad may be
   reused.  This is in fact the first case we discussed, it is just that we included
   the lines in the graph showing the loop.

   If a general use conveyance c2 were in a library and that library were separately
   maintained, the library would have to be given its own context pads in number that
   reflect the nesting levels for the library.  I.e. the library would be done separately.

   The context pad approach will use less memory than giving each conveyance it's own
   context, but it might not be an optimal solution.  For example, at run time, control
   might not ever pass into deeper nesting layers, yet their context will have been
   allocated. It would be more efficient, from a memory usage standpoint, to only allocate
   pads for deeper nesting layers when they are entered.  That would be a stack push.
   However to assure there is a corresponding stack pop, we are back to the encapsulation
   approach.

   In the current form, any computation to determine a next continuation is a ‘one out of
   n’ choice. Even if we have multiple simultaneous conveyances defined, each on a
   separate thread, it is still ‘one out of n, per thread’.  A variable that holds a
   continuation will always only hold a limited number of values, in the worst case, being
   all the conveyances available at the lexical scope the variable appears in a
   ‘convey’.


*** Context stack

   This approach is similar to functional encapsulation.  As for functions we push locals
   on the stack, i.e. push our context to be shared on the stack. Then after it is used we
   pop it off.

   Suppose then, that we push context as part of c1, then we pop the context when taking
   any continuation leaving c1.  However, that would mean that we pop the context when
   continuing to c2.  The data would be gone when we came back to c3, if indeed we ever
   came back.

   If we required that all conveyances from c2 return to conveyances that are defined in
   c1's lexical scope, then we could design into all of these captured conveyances a pop
   stack call. At that point the only difference from the functional encapsulation
   approach would be that we must use a pad for the arguments.

** Explicit message passing

   In the control flow pattern under discussion, c1 is sending a message to c3.  Now
   suppose that c3 is not defined in c1's lexical scope, and that c3 is a general use
   conveyance. Also, let us limit analysis here to a single thread of execution.

   c3 still needs two messages, one provided directly as part of being continued into from
   c2.  The other sent by c1 during an earlier point in the execution stream. c3 is
   generally available to be called from multiple sources, so it will need some way to
   know which messages correspond to which when putting them in pairs.

   In data flow systems we accomplish such alignment of messages by giving each a token,
   and then having a reservations stations in front of execution units.  Here our
   execution units are the conveyances. Only when a set of matching tokens are received,
   i.e. when all the messages in a synchronized set have arrived, do we continue with
   execution. This approach would require even more memory than dedicating a context pad
   to each conveyance.  It would also be unusual to do such a thing when we are not
   synchronizing data between separate threads of execution. It is a too heavy of a
   solution for something like our TM2x library.

   We will also need some means of allocating and deallocating messages. If explicit
   deallocation is required, c3 cannot be solely responsible for deallocating the message
   from c1, because c2 might continue elsewhere and thus the c3 conveyance might not ever
   run.

   Thus we have two unsolved problems: synchronization and deallocation.

   For synchronization we make our ContinuationPtr type hold a pair of pointers.  One
   pointer would be to the conveyance to be continued into as before.  The other
   pointer would point to the message.  Thus when c2 continues into c3 it would hand
   it both the arguments and the message. The two both came from the same continuation
   pointer, so like entangled particles, they are already synchronized.

   There is only one path of execution for a given thread.  Hence we could make the
   message for c3 a struct that contains all of the arguments independent of the source,
   c1 would then allocate the message, it would be sent to c2 and c2 would fill in
   more fields in the message, and then the message arrives at c3 where it is used.

   Suppose our message for c3 were allocated on the heap. Just before c2 continues into
   c3, c2 code would go through the unused continuation pointers and deallocate their
   messages. In general, when a conveyance continues forward to another conveyance it
   would deallocate all the messages in the unused continuation pointers.  This is a
   possible solution to the deallocation problem.

   Now consider this sequence of conveyances that is currently encapsulated in `copy_elements`:

````
      convey byte_n;

      // c1
      cdef(byte_n){
        AR(ar ,Inclusive·3opLL ,0);
        ar->a0             = cx->element_n;
        ar->a1             = cx->element_byte_n;
        ar->rpt            = &cx->byte_n;
        ar->nominal        = &&src_byte_i;
        ar->gt_address_t_n = cx->src_index_gt_n;
        convey Inclusive·mul_ib;
      }

      // c2
      cdef(src_byte_i){
        AR(ar ,Inclusive·3opLL ,0);
        ar->a0             = cx->src_element_i;
        ar->a1             = cx->element_byte_n;
        ar->rpt            = &cx->src_byte_i;
        ar->nominal        = &&dst_byte_i;
        ar->gt_address_t_n = cx->src_index_gt_n;
        convey Inclusive·mul_ei_bi;
        cend;
      }

      // c3
      cdef(dst_byte_i){
        AR(ar ,Inclusive·3opLL ,0);
        ar->a0             = cx->dst_element_i;
        ar->a1             = cx->element_byte_n;
        ar->rpt            = &cx->dst_byte_i;
        ar->nominal        = &&copy_bytes;
        ar->gt_address_t_n = cx->dst_index_gt_n;
        convey Inclusive·mul_ei_bi;
        cend;
      }

      // c4
      cdef(copy_bytes){
        AR(ar ,TM2x·construct_copy_bytes ,0);
        ar->src             = cx->src;
        ar->src_byte_i      = cx->src_byte_i;
        ar->dst             = cx->dst;
        ar->dst_byte_i      = cx->dst_byte_i;
        ar->byte_n          = cx->byte_n;
        ar->nominal         = cx->nominal;
        ar->src_index_gt_n  = cx->src_index_gt_n;
        ar->dst_index_gt_n  = cx->dst_index_gt_n;
        convey TM2x·copy_bytes;
        cend;
      }
````

  This sequence makes use of a context called `cx`.  Suppose instead of putting these in an encapsulation
  we put them in another conveyance. That conveyance would have a message attached to it through its
  conveyance pointer.  
    
````
     push(conveyance, size){
        <do the push>        
        convey *conveyance;
        cend;
      }

     pop(conveyance, size){
        <do the pop>        
        convey *conveyance;
        cend;
      }


````

````
    cdef(c0){

      convey push(byte_n ,byte_n_of(struct c0 ,cx); // cx points to the stack frame

      // c1
      cdef(byte_n){
        AR(ar ,Inclusive·3opLL ,0);
        ar->a0             = cx->element_n;
        ar->a1             = cx->element_byte_n;
        ar->rpt            = &cx->byte_n;
        ar->nominal        = &&src_byte_i;
        ar->gt_address_t_n = pop(byte_n_of(struct c0 ,cx->src_index_gt_n);    // goes elsewhere
        convey Inclusive·mul_ib;
      }

      // c2
      cdef(src_byte_i){
        AR(ar ,Inclusive·3opLL ,0);
        ar->a0             = cx->src_element_i;
        ar->a1             = cx->element_byte_n;
        ar->rpt            = &cx->src_byte_i;
        ar->nominal        = &&dst_byte_i;
        ar->gt_address_t_n = pop(byte_n_of(struct c0 ,cx->src_index_gt_n);  // goes elsewhere
        convey Inclusive·mul_ei_bi;
        cend;
      }

      // c3
      cdef(dst_byte_i){
        AR(ar ,Inclusive·3opLL ,0);
        ar->a0             = cx->dst_element_i;
        ar->a1             = cx->element_byte_n;
        ar->rpt            = &cx->dst_byte_i;
        ar->nominal        = &&copy_bytes;
        ar->gt_address_t_n = pop(byte_n_of(struct c0 ,cx->dst_index_gt_n);   // goes elsewhere
        convey Inclusive·mul_ei_bi;
        cend;
      }

      // c4
      cdef(copy_bytes){
        AR(ar ,TM2x·construct_copy_bytes ,0);
        ar->src             = cx->src;
        ar->src_byte_i      = cx->src_byte_i;
        ar->dst             = cx->dst;
        ar->dst_byte_i      = cx->dst_byte_i;
        ar->byte_n          = cx->byte_n;
        ar->nominal         = pop(byte_n_of(struct c0 ,cx->nominal);         // goes elsewhere
        ar->src_index_gt_n  = pop(byte_n_of(struct c0 ,cx->src_index_gt_n);  // goes elsewhere
        ar->dst_index_gt_n  = pop(byte_n_of(struct c0 ,cx->dst_index_gt_n);  // goes elsewhere
        convey TM2x·copy_bytes;
        cend;
      }


      cend
    }
````
Here push and pop are see gasket conveyances.  They actually receive the arguments
on lc, and they ignore ar.  The lc args are the size of the push or pop, and
the conveyance to come after.  After the push or pop, they convey to the conveyance
argument, and as the  ar pad is unchanged.

This is very close to an encapsulated function. There is no trampoline. It is a
sort of ‘this is how you wire it up’ for the compiler, and then a direct run
at run time.
